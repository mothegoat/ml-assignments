{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b07eb33c"
      },
      "source": [
        "<div>\n",
        "<img src='http://www-scf.usc.edu/~ghasemig/images/sharif.png' alt=\"SUT logo\" width=220 height=220 align=left class=\"saturate\">\n",
        "\n",
        "<br>\n",
        "<font face=\"Times New Roman\">\n",
        "<div dir=ltr align=center> \n",
        "<!-- <font color=0F5298 size=7> -->\n",
        "<font color=0F5298 size=6>\n",
        "    Introduction to Machine Learning <br> <br>\n",
        "<!-- <font color=2565AE size=5> -->\n",
        "<font size=5>\n",
        "    Computer Engineering Department <br>\n",
        "    Spring 2023 <br> <br>\n",
        "<font color=606060 size=5>\n",
        "    Homework 4: Practical - Naive Bayes <br> <br>\n",
        "<font color=686880 size=4>\n",
        "    TAs: Alireza Farashah - Arman Malekzadeh - Ali Salesi\n",
        "    \n",
        "____"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5a79508"
      },
      "source": [
        "### Full Name :\n",
        "### Student Number :\n",
        "### Colab Link: \n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note 1: In this assignment, we are trying to simulate the functionality of something called \"CountVectorizer\" which is used in natural language processing. You are advised to take a look at this link before beginning to answer the questions:\n",
        "\n",
        "https://www.geeksforgeeks.org/using-countvectorizer-to-extracting-features-from-text/\n",
        "\n",
        "Note 2: One or two TA sessions will be held related to this assignment to make sure you get familiarized with this topic. Therefore, keep calm and write code!"
      ],
      "metadata": {
        "id": "QTZBzFXNv8pP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download the Dataset"
      ],
      "metadata": {
        "id": "Dsp-qF9vLbUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O /content/dataset.zip \"https://www.dropbox.com/s/yf195wl0sp3term/dataset-train.zip?dl=1\""
      ],
      "metadata": {
        "id": "YQG4cjKvK4zZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/dataset/\n",
        "!unzip '/content/dataset.zip' -d /content/dataset/"
      ],
      "metadata": {
        "id": "GkjLDi1xBR-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "AI_tN2UDLgT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "xzZeY9pcBo-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the csv file and load it as a dataframe."
      ],
      "metadata": {
        "id": "bovAIGr4LkcU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5XkCekbTQzaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dealing with Class Imbalance"
      ],
      "metadata": {
        "id": "b2eq6fRZZroS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each \"topic\", count and display the number of news belonging to it. (5 points)"
      ],
      "metadata": {
        "id": "__mdmjwgNSRb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1f0oIh-PNYLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Balance the dataset in a way that all of the topics get associated with the same number of news. For this purpose, find the topic for which the minimum number of news exists. Then, use downsampling to lower the number of news associated with the other topics.<br>\n",
        "Finally, save the result as a new dataframe. (15 points)"
      ],
      "metadata": {
        "id": "8ETq4g97Oj0c"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XJawN5XRDFYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparation and Feature Extraction"
      ],
      "metadata": {
        "id": "9DMwlMiwZ4Ql"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the dataframe to two parts for training (80%) and testing (20%). (5 points)"
      ],
      "metadata": {
        "id": "FyrxWwjXQcfV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BXM2X_tJZIJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this part, we will extract features from the textual data using a very basic method."
      ],
      "metadata": {
        "id": "tSzLXYMhaL3R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider the following sentence:\n",
        "```\n",
        "Sometimes a dog can run faster than a cat.\n",
        "```\n",
        "In the above sentence, the \"tokens\" are:\n",
        "\n",
        "```\n",
        "\"sometimes\", \"a\", \"dog\", \"can\", \"run\", \"faster\", \"than\", \"a\", \"cat\"\n",
        "```"
      ],
      "metadata": {
        "id": "BCejmR4nhABv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find the tokens of each news article in the \"training dataframe\" by splitting it based on the occurence of the space character (5 points). For instance, the following sentence:\n",
        "```\n",
        "او به میدان رفت\n",
        "```\n",
        "gets converted to these tokens:\n",
        "```\n",
        "[\"او\",\"به\",\"میدان\",\"رفت\"]\n",
        "```"
      ],
      "metadata": {
        "id": "fTnb43swgo8r"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_dlCAqisb6cT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count the tokens and list the top 5 frequent ones (5 points)"
      ],
      "metadata": {
        "id": "eD-UebxhiUyd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rg-aJqkSiEJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider the following sentence:\n",
        "```\n",
        "تیم فوتبال بارسلونا امشب با بایرن مونیخ دیدار می‌کند.\n",
        "```\n",
        "In the above sentence, we do not need the word `با` to determine that the topic is \"sports\". This word doesn't have any impact on the category this sentence belongs to. \n",
        "This word and similar ones are called \"stopwords\". A list of stopwords for the Persian language can be found in this text file:\n",
        "https://github.com/ziaa/Persian-stopwords-collection/raw/master/Stopwords/Savoy/persianST.txt\n",
        "\n",
        "Use it to remove all tokens that are actually stopwords.\n",
        "Also, remove the `#` token. (10 points)"
      ],
      "metadata": {
        "id": "dJyE1s6Wi0ZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O /content/stopwords.txt https://github.com/ziaa/Persian-stopwords-collection/raw/master/Stopwords/Savoy/persianST.txt"
      ],
      "metadata": {
        "id": "6xV_zvIvjtH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w5TLeugQjxIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make a list of the remaining unique tokens (5 points)"
      ],
      "metadata": {
        "id": "WH6Lw66Xk-Vb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ASLpUFZgkROF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count the number of the occurences of each token in each document. This way, you can make a numpy array to represent each document. Call this new array `x_train`. (10 points)\n",
        "\n",
        "Example:\n",
        "\n",
        "Unique tokens in all documents: \n",
        "```\n",
        "0: hen\n",
        "1: sometimes\n",
        "2: a\n",
        "3: the\n",
        "4: dog\n",
        "5: runs\n",
        "6: faster\n",
        "7: than\n",
        "8: cat\n",
        "9: bird\n",
        "```\n",
        "\n",
        "Current Document: `sometimes a dog runs faster than a cat`\n",
        "\n",
        "The representation of the document:\n",
        "\n",
        "```\n",
        "[0, 1, 2, 0, 1, 1, 1, 1, 1, 0]\n",
        "```\n",
        "\n",
        "The meaning of this representation:\n",
        "\n",
        "```\n",
        "0: the document doesn't contain \"hen\"\n",
        "1: the document contains 1 \"sometimes\"\n",
        "2: the document contains 2 \"a\"\n",
        "0: the document doesn't contain \"the\"\n",
        "1: the document contains 1 \"dog\"\n",
        "1: the document contains 1 \"runs\"\n",
        "1: the document contains 1 \"faster\"\n",
        "1: the document contains 1 \"than\"\n",
        "1: the document contains 1 \"cat\"\n",
        "0: the document doesn't contain \"bird\"\n",
        "``` "
      ],
      "metadata": {
        "id": "xI9kbGYql-WU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z17IkdW-lc2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make another numpy array by converting the topics associated with the training news to numbers. For instance, if the topics are: `sports`, `economics`, `politics`, and `cultural`, convert them to `0` to `3`. Call this new array `y_train`. (5 points)"
      ],
      "metadata": {
        "id": "NXeW76p2pjnc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wV5zeofEF3Nn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the unique tokens you found in the training news, represent the testing news as another numpy array called `x_test`. (5 points)\n",
        "\n",
        "Note: Do not forget to remove stopwords and the `#` token."
      ],
      "metadata": {
        "id": "lew_jlNPqhPb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RIy2qMABrQcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert the topics associated with the testing news to their equivalent numbers (as before), and save the result as a numpy array called `y_test`. (5 points)"
      ],
      "metadata": {
        "id": "QWIRhxS_rX7M"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T0tXlWRHrWUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training and Evaluation"
      ],
      "metadata": {
        "id": "LQdf4UuQrvme"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using sklearn (10 points)"
      ],
      "metadata": {
        "id": "MwkWJbTEsoWy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a Multinomial Naive Bayes Model on the training news (`x_train` and `y_train`) using `sklearn`."
      ],
      "metadata": {
        "id": "sGcrjKBgr1uL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yJTD0NB7rW2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the predictions of the model for the testing news (`x_test`)."
      ],
      "metadata": {
        "id": "OeFDzw61sCna"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f0KP-84CsCJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the classification report containing \"precision\", \"recall\", and \"f1-score\" for each class, and their averages. (you can use `sklearn` for this part)"
      ],
      "metadata": {
        "id": "G1KAXbhJsb5o"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1fLYOmgMsWns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using your own code (15 points)"
      ],
      "metadata": {
        "id": "dM7sjbu6stRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Naive_Bayes:\n",
        "    \"\"\"\n",
        "    Fits it on data, then uses predict to get results.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        YOUR CODE (IF NECESSARY)\n",
        "        \"\"\"\n",
        "        return self\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Fit the training data\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : array-like, shape = [n_samples, n_features]\n",
        "            Training samples\n",
        "        y : array-like, shape = [n_samples, n_target_values]\n",
        "            Target values\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "        \"\"\"\n",
        "\n",
        "        n_samples, n_features = X.shape\n",
        "        \"\"\"\n",
        "        YOUR CODE\n",
        "        \"\"\"\n",
        "        \n",
        "        return self\n",
        "    \n",
        "    def predict(self, X):\n",
        "        \"\"\" Predicts the value after the model has been trained.\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : array-like, shape = [n_samples, n_features]\n",
        "            Test samples\n",
        "        Returns\n",
        "        -------\n",
        "        Predicted value\n",
        "        \"\"\"\n",
        "        \n",
        "        y_pred = None\n",
        "        \"\"\"\n",
        "        YOUR CODE\n",
        "        \"\"\"\n",
        "        return y_pred"
      ],
      "metadata": {
        "id": "LgTbqyNwsZ5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train your own Multinomial Naive Bayes Model on the training news (`x_train` and `y_train`)."
      ],
      "metadata": {
        "id": "ZYpwLACxtlFy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QBnzQoqyIl-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the predictions of your model for the testing news (`x_test`)."
      ],
      "metadata": {
        "id": "pPSZVHBCtndS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T7SMtuR0tskf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the classification report containing \"precision\", \"recall\", and \"f1-score\" for each class, and their averages. (you can use `sklearn` for this part)"
      ],
      "metadata": {
        "id": "hIlERTP1ttCW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9MfxJtbmtugx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kaggle"
      ],
      "metadata": {
        "id": "ElMEcOMAeFA1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Competition Link: https://www.kaggle.com/t/88f1b6e251e34575b2e4cb4b91aed0ef"
      ],
      "metadata": {
        "id": "64J1wFXweGsH"
      }
    }
  ]
}